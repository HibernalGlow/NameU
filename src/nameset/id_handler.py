"""
å‹ç¼©åŒ…IDå¤„ç†æ¨¡å—
å¤„ç†å‹ç¼©åŒ…æ³¨é‡Šä¸­çš„IDï¼ŒåŒ…æ‹¬è¯»å–ã€å†™å…¥å’Œç”Ÿæˆ
"""

import os
import subprocess
import tempfile
import shutil
from typing import Optional
from loguru import logger
from nanoid import generate


class ArchiveIDHandler:
    """å‹ç¼©åŒ…IDå¤„ç†ç±»"""
    
    # ç¼“å­˜å·²è¯»å–çš„æ³¨é‡Šï¼Œé¿å…é‡å¤è¯»å–
    _comment_cache: dict[str, Optional[str]] = {}
    
    @staticmethod
    def generate_id() -> str:
        """
        ç”Ÿæˆæ–°çš„å‹ç¼©åŒ…ID
        
        Returns:
            str: æ–°ç”Ÿæˆçš„å”¯ä¸€ID
        """
        # ä½¿ç”¨nanoidç”ŸæˆURLå®‰å…¨çš„å”¯ä¸€ID
        return generate(size=12)
    
    @staticmethod
    def get_archive_comment(archive_path: str) -> Optional[str]:
        """
        è·å–å‹ç¼©åŒ…æ³¨é‡Š
        
        Args:
            archive_path: å‹ç¼©åŒ…è·¯å¾„
            
        Returns:
            Optional[str]: å‹ç¼©åŒ…æ³¨é‡Šï¼Œå¤±è´¥è¿”å›None
        """
        # æ£€æŸ¥ç¼“å­˜
        if archive_path in ArchiveIDHandler._comment_cache:
            return ArchiveIDHandler._comment_cache[archive_path]
        
        try:
            # æ–¹æ³•1: ä½¿ç”¨ bz.exe è¯»å–ï¼ˆå¦‚æœæ˜¯ZIPæ–‡ä»¶ï¼‰
            if archive_path.lower().endswith('.zip'):
                # å°è¯•å¤šä¸ªå¯èƒ½çš„ bz.exe è·¯å¾„ (ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æä¾›çš„è·¯å¾„)
                bz_paths = [
                    r"D:\1Repo\Soft\bz\Bandizip\bz.exe",  # ç”¨æˆ·æŒ‡å®šè·¯å¾„
                    r"bz.exe",  # ç¯å¢ƒå˜é‡ä¸­çš„
                    r"C:\Program Files\Bandizip\bz.exe",
                    r"C:\Program Files (x86)\Bandizip\bz.exe"
                ]
                
                bz_exe = None
                for path in bz_paths:
                    if path == "bz.exe" or os.path.exists(path):
                        bz_exe = path
                        break
                
                if bz_exe:
                    logger.debug(f"ğŸ” æ‰¾åˆ° Bandizip: {bz_exe}")
                    try:
                        result = subprocess.run(
                            [bz_exe, 'l', '-list:v', archive_path],
                            capture_output=True,
                            text=True,
                            encoding='utf-8'
                        )
                        
                        if result.returncode == 0:
                            # è§£æbz.exeçš„è¾“å‡ºæŸ¥æ‰¾æ³¨é‡Š
                            output = result.stdout
                            comment_start_marker = 'Archive comment:'
                            
                            # æ‰¾åˆ°æ³¨é‡Šå¼€å§‹ä½ç½®
                            comment_index = output.find(comment_start_marker)
                            if comment_index != -1:
                                # è·å–æ³¨é‡Šå†…å®¹ï¼Œéœ€è¦å¤„ç†å¤šè¡Œæ³¨é‡Š
                                lines = output[comment_index:].splitlines()
                                if len(lines) > 1:  # ç¡®ä¿æœ‰æ³¨é‡Šå†…å®¹è¡Œ
                                    # è·³è¿‡ç¬¬ä¸€è¡Œï¼ˆåŒ…å«"Archive comment:"çš„è¡Œï¼‰
                                    comment_lines = []
                                    for line in lines[1:]:
                                        # å¦‚æœé‡åˆ°æ–°çš„æ®µè½æ ‡è®°ï¼Œåœæ­¢è¯»å–æ³¨é‡Š
                                        if line.strip() and (line.startswith('Archive:') or line.startswith('Type:') or 
                                                            line.startswith('Physical Size:') or line.startswith('Headers Size:')):
                                            break
                                        comment_lines.append(line)
                                    
                                    comment_part = '\n'.join(comment_lines).strip()
                                    if comment_part:
                                        # ä¿®å¤JSONæ ¼å¼ï¼šå¦‚æœå¼€å¤´ç¼ºå°‘å¤§æ‹¬å·ï¼Œè¡¥ä¸Š
                                        if comment_part.startswith('"id":') or comment_part.startswith('"'):
                                            comment_part = '{' + comment_part
                                        logger.debug(f"ä½¿ç”¨bz.exeè¯»å–æ³¨é‡ŠæˆåŠŸ: {archive_path}")
                                        ArchiveIDHandler._comment_cache[archive_path] = comment_part
                                        return comment_part
                    except Exception as e:
                        logger.debug(f"ä½¿ç”¨bz.exeè¯»å–æ³¨é‡Šå¤±è´¥: {e}")
                else:
                    logger.debug(f"æœªæ‰¾åˆ°å¯ç”¨ bz.exeï¼Œè·³è¿‡è¯»å–: {archive_path}")
            
            # æ–¹æ³•2: å›é€€åˆ°7zï¼ˆç”¨äºå…¶ä»–æ ¼å¼çš„å‹ç¼©åŒ…ï¼‰
            result = subprocess.run(
                ['7z', 'l', '-slt', archive_path],
                capture_output=True,
                text=True,
                encoding='utf-8',
                errors='ignore'
            )
            
            if result.returncode != 0:
                return None
            
            # è§£æè¾“å‡ºæŸ¥æ‰¾æ³¨é‡Š
            for line in result.stdout.splitlines():
                if line.startswith('Comment = '):
                    comment = line[10:].strip()  # å»æ‰"Comment = "å‰ç¼€
                    if comment:
                        logger.debug(f"ä½¿ç”¨7zè¯»å–æ³¨é‡ŠæˆåŠŸ: {archive_path}")
                        ArchiveIDHandler._comment_cache[archive_path] = comment
                        return comment
            
            ArchiveIDHandler._comment_cache[archive_path] = None
            return None
            
        except Exception as e:
            logger.error(f"è·å–å‹ç¼©åŒ…æ³¨é‡Šå¤±è´¥ {archive_path}: {e}")
            ArchiveIDHandler._comment_cache[archive_path] = None
            return None
    
    @staticmethod
    def clear_comment_cache() -> None:
        """
        æ¸…é™¤æ³¨é‡Šç¼“å­˜
        """
        ArchiveIDHandler._comment_cache.clear()
    
    @staticmethod
    def set_archive_comment(archive_path: str, comment: str) -> bool:
        """
        è®¾ç½®å‹ç¼©åŒ…æ³¨é‡Š
        
        Args:
            archive_path: å‹ç¼©åŒ…è·¯å¾„
            comment: è¦è®¾ç½®çš„æ³¨é‡Š
            
        Returns:
            bool: æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºZIPæ ¼å¼ï¼ˆbandizipä¸»è¦æ”¯æŒZIPæ³¨é‡Šï¼‰
            if not archive_path.lower().endswith('.zip'):
                logger.warning(f"è·³è¿‡éZIPæ–‡ä»¶çš„æ³¨é‡Šè®¾ç½®: {archive_path}")
                return False
            
            # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶æ–¹å¼ï¼Œå¼ºåˆ¶UTF-8ç¼–ç 
            bandizip_commands = [
                r"D:\1Repo\Soft\bz\Bandizip\bz.exe",
                r"bz.exe",
                r"C:\Program Files\Bandizip\bz.exe",
                r"C:\Program Files (x86)\Bandizip\bz.exe"
            ]
            
            for cmd in bandizip_commands:
                try:
                    # åˆ›å»ºUTF-8ç¼–ç çš„ä¸´æ—¶æ³¨é‡Šæ–‡ä»¶
                    with tempfile.NamedTemporaryFile(mode='w', encoding='utf-8', delete=False, suffix='.txt') as f:
                        f.write(comment)
                        comment_file = f.name
                    
                    try:
                        result = subprocess.run(
                            [cmd, 'a', '-y', f'-cmtfile:{comment_file}', archive_path],
                            capture_output=True,
                            text=True,
                            encoding='utf-8'
                        )
                        
                        if result.returncode == 0:
                            logger.debug(f"ğŸ” ä½¿ç”¨ {cmd} æˆåŠŸè®¾ç½®å‹ç¼©åŒ…æ³¨é‡Š: {archive_path}")
                            return True
                        else:
                            logger.debug(f"{cmd}æ–‡ä»¶æ–¹å¼è®¾ç½®æ³¨é‡Šå¤±è´¥: {result.stderr}")
                            
                    finally:
                        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                        try:
                            os.unlink(comment_file)
                        except:
                            pass
                            
                except FileNotFoundError:
                    logger.debug(f"{cmd}æœªæ‰¾åˆ°ï¼Œè·³è¿‡")
                    continue
                    
            logger.warning(f"æœªæ‰¾åˆ°å¯ç”¨çš„Bandizipå‘½ä»¤ï¼Œæ— æ³•è®¾ç½®æ³¨é‡Š: {archive_path}")
            return False
                    
        except Exception as e:
            logger.error(f"è®¾ç½®å‹ç¼©åŒ…æ³¨é‡Šå¤±è´¥ {archive_path}: {e}")
            return False
    
    @staticmethod
    def extract_id_from_comment(comment: Optional[str]) -> Optional[str]:
        """
        ä»æ³¨é‡Šä¸­æå–ID
        
        Args:
            comment: å‹ç¼©åŒ…æ³¨é‡Š
            
        Returns:
            Optional[str]: æå–çš„IDï¼Œæœªæ‰¾åˆ°è¿”å›None
        """
        if not comment:
            return None
        
        # æ”¯æŒå¤šç§IDæ ¼å¼
        # æ ¼å¼1: ID: xxxxx
        # æ ¼å¼2: archive_id: xxxxx
        # æ ¼å¼3: {"id": "xxxxx", ...}
        
        import re
        import json
        
        # å°è¯•JSONæ ¼å¼
        try:
            data = json.loads(comment)
            if isinstance(data, dict):
                return data.get('id') or data.get('archive_id')
        except:
            pass
        
        # å°è¯•ç®€å•çš„é”®å€¼å¯¹æ ¼å¼
        patterns = [
            r'(?:^|\n)ID:\s*([^\n\r]+)',
            r'(?:^|\n)archive_id:\s*([^\n\r]+)',
            r'(?:^|\n)id:\s*([^\n\r]+)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, comment, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return None
    
    @staticmethod
    def create_comment_with_id(archive_id: str, metadata: Optional[dict] = None) -> str:
        """
        åˆ›å»ºåŒ…å«IDçš„æ³¨é‡Š
        
        Args:
            archive_id: å‹ç¼©åŒ…ID
            metadata: é¢å¤–çš„å…ƒæ•°æ®
            
        Returns:
            str: æ ¼å¼åŒ–çš„æ³¨é‡Šå†…å®¹
        """
        import json
        from datetime import datetime
        
        comment_data = {
            'id': archive_id,
            'created_by': 'nameu',
            'created_at': datetime.now().isoformat()
        }
        
        if metadata:
            comment_data.update(metadata)
        
        return json.dumps(comment_data, ensure_ascii=False, indent=2)
    
    @staticmethod
    def get_or_create_archive_id(archive_path: str, metadata: Optional[dict] = None) -> Optional[str]:
        """
        è·å–æˆ–åˆ›å»ºå‹ç¼©åŒ…ID
        
        Args:
            archive_path: å‹ç¼©åŒ…è·¯å¾„
            metadata: é¢å¤–çš„å…ƒæ•°æ®
            
        Returns:
            Optional[str]: å‹ç¼©åŒ…IDï¼Œå¤±è´¥è¿”å›None
        """
        # é¦–å…ˆå°è¯•ä»æ³¨é‡Šè·å–ç°æœ‰ID
        comment = ArchiveIDHandler.get_archive_comment(archive_path)
        existing_id = ArchiveIDHandler.extract_id_from_comment(comment)
        
        if existing_id:
            logger.debug(f"æ‰¾åˆ°ç°æœ‰ID: {existing_id} ({os.path.basename(archive_path)})")
            return existing_id
        
        # ç”Ÿæˆæ–°ID
        new_id = ArchiveIDHandler.generate_id()
        new_comment = ArchiveIDHandler.create_comment_with_id(new_id, metadata)
        
        # è®¾ç½®æ³¨é‡Š
        if ArchiveIDHandler.set_archive_comment(archive_path, new_comment):
            logger.info(f"åˆ›å»ºæ–°ID: {new_id} ({os.path.basename(archive_path)})")
            return new_id
        else:
            logger.error(f"æ— æ³•è®¾ç½®å‹ç¼©åŒ…æ³¨é‡Š: {archive_path}")
            return None
    
    @staticmethod
    def update_comment_metadata(archive_path: str, metadata: dict) -> bool:
        """
        æ›´æ–°æ³¨é‡Šä¸­çš„å…ƒæ•°æ®ï¼ˆä¿æŒIDä¸å˜ï¼‰
        
        Args:
            archive_path: å‹ç¼©åŒ…è·¯å¾„
            metadata: è¦æ›´æ–°çš„å…ƒæ•°æ®
            
        Returns:
            bool: æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            import json
            from datetime import datetime
            
            # è·å–ç°æœ‰æ³¨é‡Š
            comment = ArchiveIDHandler.get_archive_comment(archive_path)
            archive_id = ArchiveIDHandler.extract_id_from_comment(comment)
            
            if not archive_id:
                logger.warning(f"æ— æ³•è·å–å‹ç¼©åŒ…IDï¼Œæ— æ³•æ›´æ–°å…ƒæ•°æ®: {archive_path}")
                return False
            
            # è§£æç°æœ‰æ•°æ®
            try:
                existing_data = json.loads(comment) if comment else {}
            except:
                existing_data = {}
            
            # æ›´æ–°æ•°æ®
            existing_data.update(metadata)
            existing_data['id'] = archive_id  # ç¡®ä¿IDä¸å˜
            existing_data['updated_at'] = datetime.now().isoformat()
            
            # è®¾ç½®æ–°æ³¨é‡Š
            new_comment = json.dumps(existing_data, ensure_ascii=False, indent=2)
            return ArchiveIDHandler.set_archive_comment(archive_path, new_comment)
            
        except Exception as e:
            logger.error(f"æ›´æ–°æ³¨é‡Šå…ƒæ•°æ®å¤±è´¥ {archive_path}: {e}")
            return False
