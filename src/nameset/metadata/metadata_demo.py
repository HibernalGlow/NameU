#!/usr/bin/env python3
"""
å¢å¼ºå…ƒæ•°æ®åŠŸèƒ½æ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¦‚ä½•ä½¿ç”¨å®Œæ•´çš„å†å²è¿½æº¯åŠŸèƒ½
"""

import os
import sys
import tempfile
import json
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from nameset.manager import ArchiveIDManager
from nameset.database import ArchiveDatabase
from loguru import logger


def create_test_archive(temp_dir: str, name: str) -> str:
    """åˆ›å»ºæµ‹è¯•ç”¨çš„å‹ç¼©åŒ…æ–‡ä»¶"""
    archive_path = os.path.join(temp_dir, name)
    with open(archive_path, 'wb') as f:
        f.write(b'PK\x03\x04')  # ZIPæ–‡ä»¶å¤´
        f.write(b'test content for ' + name.encode())
    return archive_path


def demo_complete_metadata_tracking():
    """æ¼”ç¤ºå®Œæ•´çš„å…ƒæ•°æ®è¿½è¸ªåŠŸèƒ½"""
    print("ğŸ” æ¼”ç¤ºï¼šå®Œæ•´å…ƒæ•°æ®è¿½è¸ªåŠŸèƒ½")
    print("=" * 50)
    
    with tempfile.TemporaryDirectory() as temp_dir:
        db_path = os.path.join(temp_dir, "metadata_demo.db")
        
        with ArchiveIDManager(db_path) as manager:
            # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
            original_name = "artist_work_v1.zip"
            archive_path = create_test_archive(temp_dir, original_name)
            
            print(f"ğŸ“ åˆ›å»ºæµ‹è¯•æ–‡ä»¶: {original_name}")
            
            # ç¬¬ä¸€æ¬¡é‡å‘½å - æ·»åŠ ç”»å¸ˆä¿¡æ¯
            new_name1 = "sakura_artist_work_v1.zip"
            success, archive_id = manager.process_archive_rename(
                archive_path, new_name1, artist_name="Sakura"
            )
            
            if success:
                print(f"âœ… ç¬¬ä¸€æ¬¡é‡å‘½åæˆåŠŸ: {original_name} -> {new_name1}")
                print(f"ğŸ†” åˆ†é…ID: {archive_id}")
                
                # æ›´æ–°æ–‡ä»¶è·¯å¾„
                archive_path = os.path.join(temp_dir, new_name1)
                
                # ç¬¬äºŒæ¬¡é‡å‘½å - ç‰ˆæœ¬æ›´æ–°
                new_name2 = "sakura_artist_work_v2_final.zip"
                success2, _ = manager.process_archive_rename(
                    archive_path, new_name2, artist_name="Sakura"
                )
                
                if success2:
                    print(f"âœ… ç¬¬äºŒæ¬¡é‡å‘½åæˆåŠŸ: {new_name1} -> {new_name2}")
                    archive_path = os.path.join(temp_dir, new_name2)
                    
                    # ç¬¬ä¸‰æ¬¡é‡å‘½å - åˆ†ç±»æ•´ç†
                    new_name3 = "[Sakura] artist_work_collection_2024.zip"
                    success3, _ = manager.process_archive_rename(
                        archive_path, new_name3, artist_name="Sakura"
                    )
                    
                    if success3:
                        print(f"âœ… ç¬¬ä¸‰æ¬¡é‡å‘½åæˆåŠŸ: {new_name2} -> {new_name3}")
                        
                        # è·å–å®Œæ•´çš„å…ƒæ•°æ®
                        print(f"\nğŸ“Š è·å–å®Œæ•´å†å²å…ƒæ•°æ®:")
                        complete_metadata = manager.get_complete_archive_metadata(archive_id)
                        
                        if complete_metadata:
                            print_metadata_summary(complete_metadata)
                            
                            # è·å–åç§°å˜æ›´å†å²
                            print(f"\nğŸ“ åç§°å˜æ›´å†å²:")
                            name_history = manager.get_archive_name_history(archive_id)
                            for i, change in enumerate(name_history, 1):
                                print(f"  {i}. {change['from']} -> {change['to']}")
                                print(f"     æ—¶é—´: {change['timestamp']}")
                                print(f"     åŸå› : {change['reason']}")
                                print()
                            
                            # è·å–ç»Ÿè®¡ä¿¡æ¯
                            print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
                            stats = manager.get_archive_statistics(archive_id)
                            if stats:
                                print(f"  æ€»æ“ä½œæ¬¡æ•°: {stats['total_operations']}")
                                print(f"  é‡å‘½åæ¬¡æ•°: {stats['total_renames']}")
                                print(f"  ä½¿ç”¨è¿‡çš„åç§°æ•°: {stats['unique_names']}")
                                print(f"  é¦–æ¬¡æ“ä½œ: {stats['first_operation']}")
                                print(f"  æœ€åæ“ä½œ: {stats['last_operation']}")


def print_metadata_summary(metadata: dict):
    """æ‰“å°å…ƒæ•°æ®æ‘˜è¦"""
    print(f"  ğŸ†” å‹ç¼©åŒ…ID: {metadata.get('archive_id', 'N/A')}")
    print(f"  ğŸ“… é¦–æ¬¡åˆ›å»º: {metadata.get('first_created_at', 'N/A')}")
    print(f"  ğŸ•’ å½“å‰æ—¶é—´: {metadata.get('current_timestamp', 'N/A')}")
    
    basic_info = metadata.get('basic_info', {})
    print(f"  ğŸ“„ å½“å‰åç§°: {basic_info.get('current_name', 'N/A')}")
    print(f"  ğŸ¨ ç”»å¸ˆåç§°: {basic_info.get('artist_name', 'N/A')}")
    print(f"  ğŸ“‚ æ–‡ä»¶è·¯å¾„: {basic_info.get('file_path', 'N/A')}")
    print(f"  ğŸ” æ–‡ä»¶å“ˆå¸Œ: {basic_info.get('file_hash', 'N/A')[:8]}..." if basic_info.get('file_hash') else "  ğŸ” æ–‡ä»¶å“ˆå¸Œ: N/A")
    
    current_op = metadata.get('current_operation', {})
    if current_op:
        print(f"  ğŸ”§ å½“å‰æ“ä½œ: {current_op.get('operation_type', 'N/A')}")
        print(f"  ğŸ“ æ–‡ä»¶å¤§å°: {current_op.get('file_size', 'N/A')} å­—èŠ‚")
        print(f"  ğŸ“ æ–‡ä»¶æ‰©å±•å: {current_op.get('file_extension', 'N/A')}")


def demo_metadata_persistence():
    """æ¼”ç¤ºå…ƒæ•°æ®æŒä¹…åŒ–å’Œæ¢å¤"""
    print(f"\nğŸ”„ æ¼”ç¤ºï¼šå…ƒæ•°æ®æŒä¹…åŒ–å’Œæ¢å¤")
    print("=" * 50)
    
    with tempfile.TemporaryDirectory() as temp_dir:
        db_path = os.path.join(temp_dir, "persistence_demo.db")
        
        # ç¬¬ä¸€é˜¶æ®µï¼šåˆ›å»ºå’Œä¿®æ”¹
        archive_id = None
        with ArchiveIDManager(db_path) as manager:
            archive_path = create_test_archive(temp_dir, "test_persistence.zip")
            
            success, archive_id = manager.process_archive_rename(
                archive_path, "renamed_persistence.zip", artist_name="TestArtist"
            )
            
            if success:
                print(f"âœ… åˆ›å»ºè®°å½•ï¼ŒID: {archive_id}")
        
        # ç¬¬äºŒé˜¶æ®µï¼šé‡æ–°æ‰“å¼€æ•°æ®åº“ï¼ŒéªŒè¯æ•°æ®æŒä¹…åŒ–
        if archive_id:
            with ArchiveIDManager(db_path) as manager:
                metadata = manager.get_complete_archive_metadata(archive_id)
                
                if metadata:
                    print(f"âœ… æˆåŠŸæ¢å¤å…ƒæ•°æ®")
                    print(f"  ç”»å¸ˆ: {metadata['basic_info']['artist_name']}")
                    print(f"  åˆ›å»ºæ—¶é—´: {metadata['first_created_at']}")
                    print(f"  æ“ä½œå†å²: {len(metadata['operation_history'])} æ¡è®°å½•")
                else:
                    print(f"âŒ æ— æ³•æ¢å¤å…ƒæ•°æ®")


def demo_search_with_metadata():
    """æ¼”ç¤ºåŸºäºå…ƒæ•°æ®çš„æœç´¢åŠŸèƒ½"""
    print(f"\nğŸ” æ¼”ç¤ºï¼šåŸºäºå…ƒæ•°æ®çš„æœç´¢åŠŸèƒ½")
    print("=" * 50)
    
    with tempfile.TemporaryDirectory() as temp_dir:
        db_path = os.path.join(temp_dir, "search_demo.db")
        
        with ArchiveIDManager(db_path) as manager:
            # åˆ›å»ºå¤šä¸ªæµ‹è¯•æ–‡ä»¶
            test_files = [
                ("artist1_work1.zip", "Artist1"),
                ("artist1_work2.zip", "Artist1"),
                ("artist2_work1.zip", "Artist2"),
                ("collaboration_work.zip", "Artist1"),
            ]
            
            archive_ids = []
            for filename, artist in test_files:
                archive_path = create_test_archive(temp_dir, filename)
                success, archive_id = manager.process_archive_rename(
                    archive_path, filename, artist_name=artist
                )
                if success:
                    archive_ids.append(archive_id)
                    print(f"âœ… åˆ›å»º: {filename} (ç”»å¸ˆ: {artist})")
            
            # æœç´¢æµ‹è¯•
            print(f"\nğŸ” æœç´¢ 'Artist1' çš„ä½œå“:")
            results = manager.search_archives("work", "Artist1")
            for result in results:
                print(f"  - {result['current_name']} (ID: {result['id']})")
                
                # è·å–è¯¦ç»†å…ƒæ•°æ®
                metadata = manager.get_complete_archive_metadata(result['id'])
                if metadata:
                    stats = metadata.get('statistics', {})
                    print(f"    æ“ä½œæ¬¡æ•°: {stats.get('total_operations', 0)}")


if __name__ == "__main__":
    print("ğŸš€ å¢å¼ºå…ƒæ•°æ®åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    try:
        demo_complete_metadata_tracking()
        demo_metadata_persistence()
        demo_search_with_metadata()
        
        print(f"\nâœ… æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
        print(f"\nğŸ’¡ æ–°åŠŸèƒ½ç‰¹ç‚¹:")
        print(f"   - metadata å­—æ®µç°åœ¨åŒ…å«å®Œæ•´çš„å†å²ä¿¡æ¯")
        print(f"   - å¯ä»¥è¿½æº¯æ‰€æœ‰åç§°å˜æ›´å†å²")
        print(f"   - ä¿ç•™ç¬¬ä¸€æ—¶é—´è®°å½•å’Œç”»å¸ˆä¿¡æ¯")
        print(f"   - æä¾›ç»Ÿè®¡ä¿¡æ¯å’Œæ“ä½œå†å²")
        print(f"   - æ”¯æŒå®Œæ•´çš„æ•°æ®æ¢å¤å’Œè¿½æº¯")
        
    except Exception as e:
        logger.error(f"æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
