"""
æ–‡ä»¶å¤„ç†æ¨¡å—ï¼Œæä¾›æ–‡ä»¶å’Œæ–‡ä»¶å¤¹å¤„ç†åŠŸèƒ½
"""

import os
from loguru import logger
from tqdm import tqdm
from .constants import ARCHIVE_EXTENSIONS
from .config import exclude_keywords, forbidden_artist_keywords, path_blacklist, is_path_blacklisted
from .filename_processor import (
    detect_and_decode_filename, get_unique_filename, get_unique_filename_with_samename,
    format_folder_name, has_artist_name, has_forbidden_keyword, convert_sensitive_words_to_pinyin,
    check_sensitive_word, get_sensitive_words_in_filename, get_unique_filename_with_pinyin_conversion
)
from .progress import init_progress, get_manager, FileStatus

# å¯¼å…¥å‹ç¼©åŒ…IDç®¡ç†æ¨¡å—
try:
    from nameset.integration import process_file_with_id_tracking
    ID_TRACKING_AVAILABLE = True
except ImportError:
    logger.warning("å‹ç¼©åŒ…IDç®¡ç†æ¨¡å—ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿé‡å‘½åæ–¹å¼")
    ID_TRACKING_AVAILABLE = False

# å°è¯•ç›´æ¥å¯¼å…¥IDå¤„ç†ä»¥ä¾¿åœ¨æ— éœ€é‡å‘½åæ—¶ä¹Ÿèƒ½è¡¥å†™æ³¨é‡Š
if ID_TRACKING_AVAILABLE:
    try:
        from nameset.id_handler import ArchiveIDHandler as _ArchiveIDHandler
    except ImportError:  # ç†è®ºä¸Šä¸ä¼šå‘ç”Ÿï¼Œå› ä¸ºintegrationå·²å¯å¯¼å…¥
        _ArchiveIDHandler = None
else:
    _ArchiveIDHandler = None

def process_files_in_directory(directory, artist_name, add_artist_name_enabled=True, convert_sensitive_enabled=True, threads: int = 1, track_ids: bool = True):
    """
    å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
    
    Args:
        directory: ç›®å½•è·¯å¾„
        artist_name: ç”»å¸ˆåç§°
        add_artist_name_enabled: æ˜¯å¦æ·»åŠ ç”»å¸ˆå
        convert_sensitive_enabled: æ˜¯å¦å°†æ•æ„Ÿè¯è½¬æ¢ä¸ºæ‹¼éŸ³
        
    Returns:
        int: ä¿®æ”¹çš„æ–‡ä»¶æ•°é‡
    """
    # æ£€æŸ¥è·¯å¾„é»‘åå•
    if is_path_blacklisted(directory):
        logger.warning(f"ğŸš« è·¯å¾„åœ¨é»‘åå•ä¸­ï¼Œè·³è¿‡å¤„ç†: {directory}")
        return 0

    # è·å–ç›®å½•ä¸‹æ‰€æœ‰å‹ç¼©æ–‡ä»¶ (ä½¿ç”¨ os.scandir ä»£æ›¿ os.listdir)
    files_info = []
    with os.scandir(directory) as it:
        for entry in it:
            if entry.is_file() and entry.name.lower().endswith(ARCHIVE_EXTENSIONS):
                files_info.append(entry.name)

    # å¦‚æœå¯ç”¨å¹¶è¡Œä¸”æ–‡ä»¶æ•°>1ï¼Œèµ°å¹¶è¡Œè§„åˆ’è·¯å¾„
    if threads and threads > 1 and len(files_info) > 1:
        return process_files_in_directory_parallel(
            directory=directory,
            artist_name=artist_name,
            add_artist_name_enabled=add_artist_name_enabled,
            convert_sensitive_enabled=convert_sensitive_enabled,
            threads=threads,
            track_ids=track_ids,
        )
    
    modified_files_count = 0
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯æ’é™¤çš„æ–‡ä»¶å¤¹ï¼ˆä»…ç”¨äºå†³å®šæ˜¯å¦æ·»åŠ ç”»å¸ˆåï¼‰
    is_excluded = any(keyword in directory for keyword in exclude_keywords)
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«ç¦æ­¢ç”»å¸ˆåçš„å…³é”®è¯
    has_forbidden = any(keyword in directory for keyword in forbidden_artist_keywords)
    
    # å…ˆæ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶
    files_to_modify = []
    # ç»Ÿè®¡ï¼šæœªæ”¹åä½†è¡¥å†™ID
    auto_ids_created = 0
    auto_db_records_created = 0

    # å‡†å¤‡å¯å¤ç”¨çš„ç®¡ç†å™¨ï¼ˆå‡å°‘é¢‘ç¹æ‰“å¼€ï¼‰
    if ID_TRACKING_AVAILABLE and track_ids:
        try:
            from nameset.manager import ArchiveIDManager as _ArchiveIDManager
            _manager = _ArchiveIDManager()
        except ImportError:
            _manager = None
    else:
        _manager = None

    # ç»Ÿè®¡ä¿¡æ¯
    files = files_info
    pm = get_manager()
    for filename in files:
        original_file_path = os.path.join(directory, filename)
        if pm: pm.add_file(original_file_path, directory)
        
        filename = detect_and_decode_filename(filename)
        new_filename = filename
        
        # å¯¹æ‰€æœ‰æ–‡ä»¶åº”ç”¨æ ¼å¼åŒ–ï¼ŒåŒ…æ‹¬æ’é™¤æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶
        new_filename = get_unique_filename(directory, new_filename, artist_name, is_excluded)
        
        # æ£€æŸ¥æ˜¯å¦å«æœ‰æ•æ„Ÿè¯ï¼Œå¦‚æœå¯ç”¨äº†æ•æ„Ÿè¯è½¬æ¢ï¼Œåˆ™å°†æ•æ„Ÿè¯è½¬æ¢ä¸ºæ‹¼éŸ³
        if convert_sensitive_enabled and check_sensitive_word(new_filename):
            logger.info(f"æ–‡ä»¶åå«æœ‰æ•æ„Ÿè¯ï¼Œå¼€å§‹è½¬æ¢ä¸ºæ‹¼éŸ³: {new_filename}")
            sensitive_words = get_sensitive_words_in_filename(new_filename)
            logger.info(f"æ£€æµ‹åˆ°çš„æ•æ„Ÿè¯: {', '.join(sensitive_words)}")
            new_filename = convert_sensitive_words_to_pinyin(new_filename)
            logger.info(f"è½¬æ¢åçš„æ–‡ä»¶å: {new_filename}")
            
        # åªæœ‰åœ¨éæ’é™¤æ–‡ä»¶å¤¹ã€å¯ç”¨äº†ç”»å¸ˆåæ·»åŠ ã€ä¸åŒ…å«ç¦æ­¢å…³é”®è¯æ—¶æ‰æ·»åŠ ç”»å¸ˆå
        if not is_excluded and not has_forbidden_keyword(directory) and add_artist_name_enabled and artist_name not in exclude_keywords and not has_artist_name(new_filename, artist_name):
            # å°†ç”»å¸ˆåè¿½åŠ åˆ°æ–‡ä»¶åæœ«å°¾
            base, ext = os.path.splitext(new_filename)
            new_filename = f"{base}{artist_name}{ext}"
        
        # ç¡®ä¿æ–‡ä»¶åå”¯ä¸€ï¼ˆå§‹ç»ˆä¼ å…¥åŸå§‹è·¯å¾„ä»¥æ’é™¤è‡ªèº«ï¼‰
        final_filename = get_unique_filename_with_samename(directory, new_filename, original_file_path)
        
        rename_needed = final_filename != filename
        if rename_needed:
            files_to_modify.append((filename, final_filename, original_file_path))
        else:
            # æ–‡ä»¶åæ— éœ€ä¿®æ”¹ï¼Œä½†ä»éœ€ç¡®ä¿å‹ç¼©åŒ…å·²å†™å…¥IDæ³¨é‡Šå¹¶åŒæ­¥æ•°æ®åº“
            if track_ids and ID_TRACKING_AVAILABLE and _ArchiveIDHandler and original_file_path.lower().endswith(ARCHIVE_EXTENSIONS):
                try:
                    # ä¸²è¡Œè¡¥å†™é€»è¾‘ä¿ç•™ä»¥å…¼å®¹å•çº¿ç¨‹
                    comment = _ArchiveIDHandler.get_archive_comment(original_file_path)
                    existing_id = _ArchiveIDHandler.extract_id_from_comment(comment)
                    if not existing_id:
                        created_id = _ArchiveIDHandler.get_or_create_archive_id(
                            original_file_path,
                            metadata={
                                'artist_name': artist_name if artist_name not in exclude_keywords else None,
                                'auto_add': True,
                                'reason': 'ensure_id_without_rename'
                            }
                        )
                        if created_id:
                            auto_ids_created += 1
                            logger.info(f"ä¸ºæœªæ”¹åæ–‡ä»¶è¡¥å†™ID: {os.path.basename(original_file_path)} -> {created_id}")
                            existing_id = created_id
                    
                    if existing_id and _manager:
                        info = _manager.get_archive_info(existing_id)
                        if not info:
                            _manager.db.create_archive_record(
                                existing_id,
                                original_file_path,
                                os.path.basename(original_file_path),
                                artist_name if artist_name not in exclude_keywords else None
                            )
                            auto_db_records_created += 1
                    
                    if pm: pm.update_status(original_file_path, FileStatus.DONE)
                except Exception as e:
                    if pm: pm.update_status(original_file_path, FileStatus.FAILED)
                    logger.error(f"è¡¥å†™IDæ—¶å‡ºé”™ {original_file_path}: {e}")

    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯ï¼ˆä»…å½“å‰ç›®å½•ä½œç”¨åŸŸï¼‰
    if (auto_ids_created + auto_db_records_created) > 0:
        logger.info(
            f"æœªæ”¹åè¡¥å†™ç»Ÿè®¡ -> æ–°å»ºID: {auto_ids_created} ä¸ª, æ•°æ®åº“è¡¥å»ºè®°å½•: {auto_db_records_created} ä¸ª (ç›®å½•: {directory})"
        )

    # å…³é—­ç®¡ç†å™¨
    if track_ids and ID_TRACKING_AVAILABLE and '_manager' in locals() and _manager:
        try:
            _manager.close()
        except Exception:
            pass

    # å¦‚æœæœ‰æ–‡ä»¶éœ€è¦ä¿®æ”¹ï¼Œæ˜¾ç¤ºè¿›åº¦æ¡å¹¶å¤„ç†
    if files_to_modify:
        with tqdm(total=len(files_to_modify), desc=f"é‡å‘½åæ–‡ä»¶", unit="file", ncols=0, leave=True) as pbar:
            for filename, new_filename, original_file_path in files_to_modify:
                # è·å–åŸå§‹æ–‡ä»¶çš„æ—¶é—´æˆ³
                original_stat = os.stat(original_file_path)
                
                new_file_path = os.path.join(directory, new_filename)
                
                try:
                    if pm: pm.update_status(original_file_path, FileStatus.PROCESSING)
                    # æ£€æŸ¥æ˜¯å¦ä¸ºå‹ç¼©æ–‡ä»¶å¹¶ä¸”å¯ç”¨äº†IDè·Ÿè¸ª
                    is_archive = original_file_path.lower().endswith(ARCHIVE_EXTENSIONS)
                    
                    if is_archive and ID_TRACKING_AVAILABLE and track_ids:
                        # ä½¿ç”¨IDè·Ÿè¸ªçš„é‡å‘½åæ–¹å¼
                        success = process_file_with_id_tracking(
                            original_file_path, 
                            new_filename, 
                            artist_name if artist_name not in exclude_keywords else None
                        )
                        if success:
                            new_file_path = os.path.join(directory, new_filename)
                            if pm: pm.update_status(original_file_path, FileStatus.DONE)
                        else:
                            logger.error(f"IDè·Ÿè¸ªé‡å‘½åå¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹å¼: {filename}")
                            # å›é€€åˆ°ä¼ ç»Ÿé‡å‘½åæ–¹å¼
                            os.rename(original_file_path, new_file_path)
                            if pm: pm.update_status(original_file_path, FileStatus.DONE)
                    else:
                        # ä¼ ç»Ÿé‡å‘½åæ–¹å¼
                        os.rename(original_file_path, new_file_path)
                        if pm: pm.update_status(original_file_path, FileStatus.DONE)
                    
                    # æ¢å¤æ—¶é—´æˆ³ï¼ˆå¯¹äºä¼ ç»Ÿæ–¹å¼ï¼‰
                    if not (is_archive and ID_TRACKING_AVAILABLE and track_ids):
                        os.utime(new_file_path, (original_stat.st_atime, original_stat.st_mtime))
                    
                    try:
                        # å°è¯•è·å–ç›¸å¯¹è·¯å¾„ä»¥ä¾¿æ›´æ¸…æ™°çš„æ—¥å¿—æ˜¾ç¤º
                        base_path = os.path.dirname(os.path.dirname(directory))
                        rel_old_path = os.path.relpath(original_file_path, base_path)
                        rel_new_path = os.path.relpath(new_file_path, base_path)
                    except ValueError:
                        rel_old_path = original_file_path
                        rel_new_path = new_file_path
                        
                    log_message = f"é‡å‘½å: {rel_old_path} -> {rel_new_path}"
                    logger.info(log_message)
                except OSError as e:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ–‡ä»¶å·²å­˜åœ¨é”™è¯¯ (WinError 183)
                    if e.winerror == 183 or "æ–‡ä»¶å·²å­˜åœ¨" in str(e):
                        # è®°å½•å†²çª
                        with _conflict_lock:
                            _conflict_records.append({
                                'source': original_file_path,
                                'target': new_file_path,
                                'error': str(e)
                            })
                        logger.error(f"âŒ æ–‡ä»¶é‡å‘½åå¤±è´¥: {e}: '{original_file_path}' -> '{new_file_path}'")
                    else:
                        logger.error(f"é‡å‘½åæ–‡ä»¶å¤±è´¥ {original_file_path}: {str(e)}")
                    continue
                except Exception as e:
                    logger.error(f"é‡å‘½åæ–‡ä»¶å¤±è´¥ {original_file_path}: {str(e)}")
                    continue
                    
                # æ›´æ–°è¿›åº¦æ¡ï¼Œä½†ä¸æ˜¾ç¤ºæ–‡ä»¶åï¼ˆé¿å…é‡å¤ï¼‰
                pbar.update(1)
                modified_files_count += 1

    return modified_files_count

# ======================= å¹¶è¡Œå®ç° =======================
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

_unique_name_lock = Lock()  # ä»…åœ¨æç«¯æƒ…å†µéœ€è¦å†è®¡ç®—å”¯ä¸€åæ—¶ä¿æŠ¤
_conflict_records = []  # è®°å½•å†²çªçš„æ–‡ä»¶è·¯å¾„
_conflict_lock = Lock()  # ä¿æŠ¤å†²çªè®°å½•åˆ—è¡¨

def _build_plan(directory, artist_name, add_artist_name_enabled, convert_sensitive_enabled, track_ids: bool = True):
    """ç¬¬ä¸€é˜¶æ®µï¼šä¸²è¡Œè®¡ç®—æœ€ç»ˆç›®æ ‡æ–‡ä»¶å & éœ€è¦é‡å‘½åçš„åˆ—è¡¨ã€‚
    é€šè¿‡ç¼“å­˜ directory å†…å®¹é¿å… O(N^2) é‡å¤æ‰«æï¼Œå¹¶ä½¿ç”¨ os.scandir åŠ é€Ÿã€‚"""
    plan = []  # æ¯é¡¹: {original_path, original_name, target_name, is_archive, needs_rename}
    
    is_excluded = any(keyword in directory for keyword in exclude_keywords)
    has_forbidden = any(keyword in directory for keyword in forbidden_artist_keywords)

    # 1. å¿«é€Ÿæ‰«æç›®å½•å¹¶å»ºç«‹ç¼“å­˜
    from .filename_processor import normalize_filename
    existing_names = set()
    normalized_cache = {}  # normalized -> [actual_names]
    
    entries = []
    with os.scandir(directory) as it:
        for entry in it:
            if entry.is_file() and entry.name.lower().endswith(ARCHIVE_EXTENSIONS):
                name = entry.name
                existing_names.add(name)
                norm = normalize_filename(name)
                if norm not in normalized_cache:
                    normalized_cache[norm] = []
                normalized_cache[norm].append(name)
                entries.append(entry)

    # 2. è®¡ç®—è§„åˆ’
    for entry in entries:
        filename = entry.name
        full_path = entry.path
        
        decoded = detect_and_decode_filename(filename)
        # ä¼ å…¥ç¼“å­˜åŠ é€Ÿè®¡ç®—
        new_filename = get_unique_filename(directory, decoded, artist_name, is_excluded, 
                                          existing_names=existing_names, normalized_cache=normalized_cache)
        
        if convert_sensitive_enabled and check_sensitive_word(new_filename):
            new_filename = convert_sensitive_words_to_pinyin(new_filename)
            
        if (not is_excluded and not has_forbidden and add_artist_name_enabled and artist_name not in exclude_keywords
                and not has_artist_name(new_filename, artist_name)):
            base, ext = os.path.splitext(new_filename)
            new_filename = f"{base}{artist_name}{ext}"
            
        # ä¼ å…¥ç¼“å­˜åŠ é€Ÿè®¡ç®—
        final_filename = get_unique_filename_with_samename(directory, new_filename, full_path,
                                                          existing_names=existing_names, normalized_cache=normalized_cache)
        
        rename_needed = final_filename != decoded
        
        # æ— è®ºæ˜¯å¦æ”¹åï¼Œéƒ½åŠ å…¥ plan (ID è¡¥å†™å°†åœ¨å¹¶è¡Œ worker ä¸­å¤„ç†)
        if rename_needed or (track_ids and ID_TRACKING_AVAILABLE):
            plan.append({
                'original_path': full_path,
                'original_name': decoded,
                'target_name': final_filename,
                'is_archive': True,
                'needs_rename': rename_needed
            })
            # å¦‚æœæ˜¯æ”¹åï¼Œæ›´æ–°ç¼“å­˜ä»¥é˜²åç»­å†²çª
            if rename_needed:
                existing_names.add(final_filename)
                norm_final = normalize_filename(final_filename)
                if norm_final not in normalized_cache:
                    normalized_cache[norm_final] = []
                normalized_cache[norm_final].append(final_filename)
        
        # æ³¨å†Œåˆ°è¿›åº¦ç®¡ç†å™¨
        pm = get_manager()
        if pm:
            pm.add_file(full_path, directory)

    return plan

def _worker_rename(entry, directory, artist_name, track_ids: bool = True):
    original_path = entry['original_path']
    target_name = entry['target_name']
    target_path = os.path.join(directory, target_name)
    needs_rename = entry.get('needs_rename', True)
    
    pm = get_manager()
    if pm: pm.update_status(original_path, FileStatus.PROCESSING)
    
    try:
        if not os.path.exists(original_path):
            if pm: pm.update_status(original_path, FileStatus.FAILED)
            return False, 'missing'
        
        # å¦‚æœéœ€è¦æ”¹å
        if needs_rename:
            original_stat = os.stat(original_path)
            if ID_TRACKING_AVAILABLE and track_ids:
                success = process_file_with_id_tracking(
                    original_path,
                    target_name,
                    artist_name if artist_name not in exclude_keywords else None
                )
                if success:
                    if pm: pm.update_status(original_path, FileStatus.DONE)
                    return True, 'renamed_with_id'
                else:
                    os.rename(original_path, target_path)
                    os.utime(target_path, (original_stat.st_atime, original_stat.st_mtime))
                    if pm: pm.update_status(original_path, FileStatus.DONE)
                    return True, 'fallback'
            else:
                os.rename(original_path, target_path)
                os.utime(target_path, (original_stat.st_atime, original_stat.st_mtime))
                if pm: pm.update_status(original_path, FileStatus.DONE)
                return True, 'renamed'
        else:
            # ä¸éœ€è¦æ”¹åï¼Œä½†å¯èƒ½éœ€è¦è¡¥ ID
            if track_ids and ID_TRACKING_AVAILABLE and _ArchiveIDHandler:
                comment = _ArchiveIDHandler.get_archive_comment(original_path)
                existing_id = _ArchiveIDHandler.extract_id_from_comment(comment)
                if not existing_id:
                    created_id = _ArchiveIDHandler.get_or_create_archive_id(
                        original_path,
                        metadata={'artist_name': artist_name if artist_name not in exclude_keywords else None,
                                  'auto_add': True,
                                  'reason': 'parallel_id_fill'}
                    )
                    if created_id:
                        if pm: pm.update_status(original_path, FileStatus.DONE)
                        return True, 'id_filled'
            if pm: pm.update_status(original_path, FileStatus.DONE)
            return True, 'no_change'

    except Exception as e:
        if pm: pm.update_status(original_path, FileStatus.FAILED)
        if isinstance(e, OSError) and (e.winerror == 183 or "æ–‡ä»¶å·²å­˜åœ¨" in str(e)):
            with _conflict_lock:
                _conflict_records.append({'source': original_path, 'target': target_path, 'error': str(e)})
        return False, str(e)

def process_files_in_directory_parallel(directory, artist_name, add_artist_name_enabled=True, convert_sensitive_enabled=True, threads: int = 16, track_ids: bool = True):
    """å¹¶è¡Œå¤„ç†ç›®å½•ä¸‹æ‰€æœ‰å‹ç¼©åŒ…æ–‡ä»¶ (ä¸¤é˜¶æ®µ: è§„åˆ’ + å¹¶è¡Œæ‰§è¡Œ)"""
    global _conflict_records
    # æ¯æ¬¡å¤„ç†æ–°ç›®å½•æ—¶æ¸…ç©ºå†²çªè®°å½•
    with _conflict_lock:
        _conflict_records = []
    
    plan = _build_plan(directory, artist_name, add_artist_name_enabled, convert_sensitive_enabled, track_ids=track_ids)
    if not plan:
        return 0
    total = len(plan)
    modified = 0
    from tqdm import tqdm as _tq
    with ThreadPoolExecutor(max_workers=threads) as executor:
        futures = [executor.submit(_worker_rename, entry, directory, artist_name, track_ids) for entry in plan]
        with _tq(total=total, desc=f"å¹¶è¡Œé‡å‘½å x{threads}", unit="file", ncols=0, leave=True) as bar:
            for fut in as_completed(futures):
                ok, info = fut.result()
                if ok:
                    modified += 1
                bar.update(1)
    logger.info(f"âœ… å¹¶è¡Œå®Œæˆ: {modified}/{total} (ç›®å½•: {directory})")
    return modified

def process_artist_folder(artist_path, artist_name, add_artist_name_enabled=True, convert_sensitive_enabled=True, threads: int = 1, track_ids: bool = True):
    """é€’å½’å¤„ç†ç”»å¸ˆæ–‡ä»¶å¤¹åŠå…¶æ‰€æœ‰å­æ–‡ä»¶å¤¹
    
    Args:
        artist_path: ç”»å¸ˆæ–‡ä»¶å¤¹è·¯å¾„
        artist_name: ç”»å¸ˆåç§°
        add_artist_name_enabled: æ˜¯å¦æ·»åŠ ç”»å¸ˆå
        convert_sensitive_enabled: æ˜¯å¦å°†æ•æ„Ÿè¯è½¬æ¢ä¸ºæ‹¼éŸ³
    """
    total_modified_files_count = 0

    # æ£€æŸ¥è·¯å¾„é»‘åå•
    if is_path_blacklisted(artist_path):
        logger.warning(f"ğŸš« ç”»å¸ˆè·¯å¾„åœ¨é»‘åå•ä¸­ï¼Œè·³è¿‡å¤„ç†: {artist_path}")
        return 0

    try:
        # æ£€æŸ¥å½“å‰æ–‡ä»¶å¤¹æ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
        if any(keyword in artist_path for keyword in exclude_keywords):
            return 0

        for root, dirs, files in os.walk(artist_path, topdown=True):
            # å¦‚æœå½“å‰ç›®å½•åŒ…å«æ’é™¤å…³é”®è¯ï¼Œè·³è¿‡æ•´ä¸ªç›®å½•
            if any(keyword in root for keyword in exclude_keywords):
                continue
            
            # å¤„ç†å­æ–‡ä»¶å¤¹åç§°
            for i, dir_name in enumerate(dirs):
                # è·³è¿‡æ’é™¤çš„æ–‡ä»¶å¤¹
                if any(keyword in dir_name for keyword in exclude_keywords):
                    continue
                    
                # è·å–å®Œæ•´è·¯å¾„
                old_path = os.path.join(root, dir_name)
                
                # å¦‚æœä¸æ˜¯ä¸€çº§ç›®å½•ï¼Œåˆ™åº”ç”¨æ ¼å¼åŒ–
                if root != artist_path:
                    new_name = format_folder_name(dir_name)
                    
                    # æ£€æµ‹ç›®å½•åæ˜¯å¦åŒ…å«æ•æ„Ÿè¯å¹¶è½¬æ¢
                    if convert_sensitive_enabled and check_sensitive_word(new_name):
                        logger.info(f"ç›®å½•åå«æœ‰æ•æ„Ÿè¯ï¼Œå¼€å§‹è½¬æ¢ä¸ºæ‹¼éŸ³: {new_name}")
                        sensitive_words = get_sensitive_words_in_filename(new_name)
                        logger.info(f"æ£€æµ‹åˆ°çš„æ•æ„Ÿè¯: {', '.join(sensitive_words)}")
                        new_name = convert_sensitive_words_to_pinyin(new_name)
                        logger.info(f"è½¬æ¢åçš„ç›®å½•å: {new_name}")
                    
                    if new_name != dir_name:
                        new_path = os.path.join(root, new_name)
                        try:
                            # ä¿å­˜åŸå§‹æ—¶é—´æˆ³
                            dir_stat = os.stat(old_path)
                            # é‡å‘½åæ–‡ä»¶å¤¹
                            os.rename(old_path, new_path)
                            # æ¢å¤æ—¶é—´æˆ³
                            os.utime(new_path, (dir_stat.st_atime, dir_stat.st_mtime))
                            # æ›´æ–° dirs åˆ—è¡¨ä¸­çš„åç§°ï¼Œç¡®ä¿ os.walk ç»§ç»­æ­£å¸¸å·¥ä½œ
                            dirs[i] = new_name
                            logger.info(f"é‡å‘½åæ–‡ä»¶å¤¹: {old_path} -> {new_path}")
                        except Exception as e:
                            logger.error(f"é‡å‘½åæ–‡ä»¶å¤¹å‡ºé”™ {old_path}: {str(e)}")
                
            # å¤„ç†å½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰å‹ç¼©æ–‡ä»¶
            pm = get_manager()
            if pm:
                pm.add_directory(root, os.path.dirname(root) if root != artist_path else None)

            modified_files_count = process_files_in_directory(root, artist_name, add_artist_name_enabled, convert_sensitive_enabled, threads=threads, track_ids=track_ids)
            total_modified_files_count += modified_files_count
    except Exception as e:
        logger.error(f"å¤„ç†æ–‡ä»¶å¤¹å‡ºé”™: {e}")

    return total_modified_files_count

def process_folders(base_path, add_artist_name_enabled=True, convert_sensitive_enabled=True, threads: int = 1, track_ids: bool = True):
    """
    å¤„ç†åŸºç¡€è·¯å¾„ä¸‹çš„æ‰€æœ‰ç”»å¸ˆæ–‡ä»¶å¤¹ã€‚
    ä¸ä½¿ç”¨å¤šçº¿ç¨‹ï¼Œé€ä¸ªå¤„ç†æ¯ä¸ªç”»å¸ˆçš„æ–‡ä»¶ã€‚
    
    Args:
        base_path: åŸºç¡€è·¯å¾„
        add_artist_name_enabled: æ˜¯å¦æ·»åŠ ç”»å¸ˆå
        convert_sensitive_enabled: æ˜¯å¦å°†æ•æ„Ÿè¯è½¬æ¢ä¸ºæ‹¼éŸ³
    """
    global _conflict_records
    # å¼€å§‹å¤„ç†å‰æ¸…ç©ºæ‰€æœ‰å†²çªè®°å½•
    with _conflict_lock:
        _conflict_records = []
    
    # è·å–æ‰€æœ‰ç”»å¸ˆæ–‡ä»¶å¤¹
    artist_folders = [
        folder for folder in os.listdir(base_path)
        if os.path.isdir(os.path.join(base_path, folder))
    ]

    total_processed = 0
    total_modified = 0
    total_files = 0
    total_sensitive = 0

    # é€ä¸ªå¤„ç†ç”»å¸ˆæ–‡ä»¶å¤¹ (å¢åŠ å…¨å±€è¿›åº¦æ¡)
    USE_TREE_UI = False  # å…³é—­æ–‡ä»¶æ ‘æ˜¾ç¤ºï¼Œä½¿ç”¨ç®€å•è¿›åº¦æ¡
    pm = init_progress(enable=USE_TREE_UI)
    pm.start()
    try:
        # å½“ USE_TREE_UI ä¸º False æ—¶ï¼Œtqdm ä¼šæ˜¾ç¤ºæ ‡å‡†è¿›åº¦æ¡
        with tqdm(total=len(artist_folders), desc="æ€»ä½“è¿›åº¦", unit="folder", position=0, leave=True, ncols=0, disable=USE_TREE_UI) as gbar:
            for folder in artist_folders:
                try:
                    artist_path = os.path.join(base_path, folder)
                    artist_name = get_artist_name(base_path, artist_path)
                    
                    # æ³¨å†Œç”»å¸ˆç›®å½•
                    pm.add_directory(artist_path)

                    # å¤„ç†ç”»å¸ˆæ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶ï¼Œå¹¶è·å–ä¿®æ”¹æ–‡ä»¶æ•°é‡
                    modified_files_count = process_artist_folder(artist_path, artist_name, add_artist_name_enabled, convert_sensitive_enabled, threads=threads, track_ids=track_ids)
                    total_processed += 1
                    total_modified += modified_files_count
                    
                    # ç»Ÿè®¡è¯¥æ–‡ä»¶å¤¹ä¸­çš„å‹ç¼©æ–‡ä»¶æ€»æ•°
                    for root, _, files in os.walk(artist_path):
                        total_files += len([f for f in files if f.lower().endswith(ARCHIVE_EXTENSIONS)])
                    
                except Exception as e:
                    logger.error(f"å¤„ç†æ–‡ä»¶å¤¹ {folder} å‡ºé”™: {e}")
                finally:
                    gbar.update(1)
    finally:
        pm.stop()
    
    # è¾“å‡ºå†²çªè®°å½•åˆ° conflict.txt
    if _conflict_records:
        conflict_file_path = os.path.join(base_path, 'conflict.txt')
        try:
            with open(conflict_file_path, 'w', encoding='utf-8') as f:
                f.write(f"æ–‡ä»¶é‡å‘½åå†²çªè®°å½•\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {_get_timestamp()}\n")
                f.write(f"æ€»å†²çªæ•°: {len(_conflict_records)}\n")
                f.write("=" * 80 + "\n\n")
                
                for i, conflict in enumerate(_conflict_records, 1):
                    f.write(f"å†²çª #{i}\n")
                    f.write(f"æºæ–‡ä»¶: {conflict['source']}\n")
                    f.write(f"ç›®æ ‡æ–‡ä»¶: {conflict['target']}\n")
                    f.write(f"é”™è¯¯ä¿¡æ¯: {conflict['error']}\n")
                    f.write("-" * 80 + "\n")
            
            logger.warning(f"âš ï¸  å‘ç° {len(_conflict_records)} ä¸ªæ–‡ä»¶é‡å‘½åå†²çªï¼Œè¯¦æƒ…å·²ä¿å­˜åˆ°: {conflict_file_path}")
            print(f"\nâš ï¸  è­¦å‘Š: å‘ç° {len(_conflict_records)} ä¸ªæ–‡ä»¶é‡å‘½åå†²çª")
            print(f"   å†²çªè¯¦æƒ…å·²ä¿å­˜åˆ°: {conflict_file_path}")
        except Exception as e:
            logger.error(f"ä¿å­˜å†²çªè®°å½•å¤±è´¥: {e}")
            
    print(f"\nå¤„ç†å®Œæˆ:")
    print(f"- æ€»å…±å¤„ç†äº† {total_processed} ä¸ªæ–‡ä»¶å¤¹")
    print(f"- æ‰«æäº† {total_files} ä¸ªå‹ç¼©æ–‡ä»¶")
    if total_modified > 0:
        print(f"- é‡å‘½åäº† {total_modified} ä¸ªæ–‡ä»¶")
    else:
        print(f"- âœ¨ æ‰€æœ‰æ–‡ä»¶åéƒ½ç¬¦åˆè§„èŒƒï¼Œæ²¡æœ‰æ–‡ä»¶éœ€è¦é‡å‘½å")

def _get_timestamp():
    """è·å–å½“å‰æ—¶é—´æˆ³å­—ç¬¦ä¸²"""
    from datetime import datetime
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def export_conflict_records(output_path: str = None) -> bool:
    """
    å¯¼å‡ºå†²çªè®°å½•åˆ°æ–‡ä»¶
    
    Args:
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨å½“å‰ç›®å½•çš„ conflict.txt
        
    Returns:
        bool: æ˜¯å¦æˆåŠŸå¯¼å‡º
    """
    global _conflict_records
    
    if not _conflict_records:
        logger.info("æ²¡æœ‰å†²çªè®°å½•éœ€è¦å¯¼å‡º")
        return False
    
    if output_path is None:
        output_path = os.path.join(os.getcwd(), 'conflict.txt')
    
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(f"æ–‡ä»¶é‡å‘½åå†²çªè®°å½•\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {_get_timestamp()}\n")
            f.write(f"æ€»å†²çªæ•°: {len(_conflict_records)}\n")
            f.write("=" * 80 + "\n\n")
            
            for i, conflict in enumerate(_conflict_records, 1):
                f.write(f"å†²çª #{i}\n")
                f.write(f"æºæ–‡ä»¶: {conflict['source']}\n")
                f.write(f"ç›®æ ‡æ–‡ä»¶: {conflict['target']}\n")
                f.write(f"é”™è¯¯ä¿¡æ¯: {conflict['error']}\n")
                f.write("-" * 80 + "\n")
        
        logger.info(f"âœ… å†²çªè®°å½•å·²å¯¼å‡ºåˆ°: {output_path}")
        return True
    except Exception as e:
        logger.error(f"å¯¼å‡ºå†²çªè®°å½•å¤±è´¥: {e}")
        return False

def get_conflict_count() -> int:
    """
    è·å–å½“å‰å†²çªè®°å½•æ•°é‡
    
    Returns:
        int: å†²çªæ•°é‡
    """
    return len(_conflict_records)

def clear_conflict_records():
    """æ¸…ç©ºå†²çªè®°å½•"""
    global _conflict_records
    with _conflict_lock:
        _conflict_records = []
    logger.debug("å†²çªè®°å½•å·²æ¸…ç©º")

def get_artist_name(target_directory, archive_path):
    """
    ä»å‹ç¼©æ–‡ä»¶è·¯å¾„ä¸­æå–è‰ºæœ¯å®¶åç§°ã€‚
    è·å–åŸºäºç›¸å¯¹è·¯å¾„çš„ç¬¬ä¸€éƒ¨åˆ†ä½œä¸ºè‰ºæœ¯å®¶åç§°ã€‚
    """
    try:
        # è·å–ç›¸å¯¹è·¯å¾„çš„ç¬¬ä¸€éƒ¨åˆ†ä½œä¸ºè‰ºæœ¯å®¶åç§°
        rel_path = os.path.relpath(archive_path, target_directory)
        artist_name = rel_path.split(os.sep)[0]
        
        # å¦‚æœæ˜¯æ–¹æ‹¬å·åŒ…å›´çš„åç§°ï¼Œç›´æ¥è¿”å›
        if artist_name.startswith('[') and artist_name.endswith(']'):
            return artist_name
            
        # å¦‚æœä¸æ˜¯æ–¹æ‹¬å·åŒ…å›´çš„ï¼ŒåŠ ä¸Šæ–¹æ‹¬å·
        return f"[{artist_name}]"
    except Exception as e:
        logger.error(f"æå–è‰ºæœ¯å®¶åç§°æ—¶å‡ºé”™: {e}")
        return ""

def record_folder_timestamps(target_directory):
    """è®°å½•target_directoryä¸‹æ‰€æœ‰æ–‡ä»¶å¤¹çš„æ—¶é—´æˆ³ã€‚"""
    folder_timestamps = {}
    for root, dirs, files in os.walk(target_directory):
        for dir in dirs:
            try:
                folder_path = os.path.join(root, dir)
                folder_stat = os.stat(folder_path)
                folder_timestamps[folder_path] = (folder_stat.st_atime, folder_stat.st_mtime)
            except FileNotFoundError:
                logger.warning(f"æ‰¾ä¸åˆ°æ–‡ä»¶å¤¹: {folder_path}")
                continue
            except Exception as e:
                logger.error(f"å¤„ç†æ–‡ä»¶å¤¹æ—¶å‡ºé”™ {folder_path}: {str(e)}")
                continue
    
    return folder_timestamps

def restore_folder_timestamps(folder_timestamps):
    """æ¢å¤ä¹‹å‰è®°å½•çš„æ–‡ä»¶å¤¹æ—¶é—´æˆ³ã€‚"""
    for folder_path, (atime, mtime) in folder_timestamps.items():
        try:
            if os.path.exists(folder_path):
                os.utime(folder_path, (atime, mtime))
        except Exception as e:
            logger.error(f"æ¢å¤æ–‡ä»¶å¤¹æ—¶é—´æˆ³æ—¶å‡ºé”™ {folder_path}: {str(e)}")
            continue
